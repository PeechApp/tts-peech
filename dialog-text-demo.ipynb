{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "from IPython.display import Audio\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from models.config import PreprocessingConfig\n",
    "from models.tts.delightful_tts.delightful_tts_refined import DelightfulTTS\n",
    "from models.vocoder.univnet import UnivNet\n",
    "from training.loss import Metrics\n",
    "from training.preprocess import TacotronSTFT\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "sample_rate = 22050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2484"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"training/datasets/speaker_id_mapping_libri.json\") as f:\n",
    "    id_mapping = json.load(f)\n",
    "len(id_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add the checkpoints to the `/checkpoints` folder and choose the appropriate version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoints to use for demo\n",
    "checkpoint_name = \"logs_new_training_libri-360-swa_19_sec_epoch=190-step=70670\"\n",
    "checkpoint_univnet = \"epoch=23-step=11616\"\n",
    "\n",
    "\n",
    "# checkpoint_path = f\"./logs_100/{checkpoint_name}.ckpt\"\n",
    "# checkpoint_path = f\"./logs_360_energy/{checkpoint_name}.ckpt\"\n",
    "# checkpoint_path = f\"./logs/{checkpoint_name}.ckpt\"\n",
    "checkpoint_path = f\"./checkpoints/{checkpoint_name}.ckpt\"\n",
    "checkpoint_path_univnet = f\"./checkpoints/{checkpoint_univnet}.ckpt\"\n",
    "\n",
    "# Dataset url to use for demo\n",
    "# dataset_url = \"train-clean-100\"\n",
    "dataset_url = \"train-clean-100\"\n",
    "\n",
    "# text_tts = \"\"\"\n",
    "# Casablanca: “But what about us?”\n",
    "# “We’ll always have Paris.”\n",
    "# The Wizard of Oz: “Lions? And Tigers? And Bears?”\n",
    "# “Oh my!”\n",
    "# Star Wars (A New Hope): “He’s almost in range.”\n",
    "# “That’s no moon; it’s a space station.”\n",
    "# Love Story: “Jenny, I’m sorry.”\n",
    "# “Don’t. Love means never having to say you’re sorry.”\n",
    "# No Country for Old Men: “Look, I need to know what I stand to win.”\n",
    "# “Everything.”\n",
    "# Forrest Gump: “I thought I’d try out my sea legs.”\n",
    "# “But you ain’t got no legs, Lieutenant Dan.”\n",
    "# Toy Story: “Buzz, you’re flying!”\n",
    "# “This isn’t flying; this is falling with style.”\n",
    "# As the snake shook its head, a deafening shout behind Harry made both of them jump.\n",
    "# ‘DUDLEY! MR DURSLEY! COME AND LOOK AT THIS SNAKE! YOU WON’T BELIEVE WHAT IT’S DOING!’\n",
    "# \"\"\"\n",
    "\n",
    "text_tts = \"\"\"\n",
    "Casablanca: “But what about us?”\n",
    "“We’ll always have Paris.”\n",
    "The Wizard of Oz: “Lions? And Tigers? And Bears?”\n",
    "“Oh my!”\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load from the checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/you/anaconda3/envs/tts_framework/lib/python3.11/site-packages/lightning/pytorch/utilities/migration/utils.py:55: The loaded checkpoint was produced with Lightning v2.2.0.post0, which is newer than your current Lightning version: v2.1.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint: ./checkpoints/logs_new_training_libri-360-swa_19_sec_epoch=190-step=70670.ckpt\n"
     ]
    }
   ],
   "source": [
    "model = DelightfulTTS.load_from_checkpoint(checkpoint_path, strict=False).to(device)\n",
    "model.eval()\n",
    "\n",
    "model.vocoder_module = UnivNet()\n",
    "model.vocoder_module.eval()\n",
    "\n",
    "print(f\"Loaded checkpoint: {checkpoint_path}\")\n",
    "\n",
    "preprocess_config = PreprocessingConfig(\"english_only\")\n",
    "tacotronSTFT = TacotronSTFT(\n",
    "    filter_length=preprocess_config.stft.filter_length,\n",
    "    hop_length=preprocess_config.stft.hop_length,\n",
    "    win_length=preprocess_config.stft.win_length,\n",
    "    n_mel_channels=preprocess_config.stft.n_mel_channels,\n",
    "    sampling_rate=preprocess_config.sampling_rate,\n",
    "    mel_fmin=preprocess_config.stft.mel_fmin,\n",
    "    mel_fmax=preprocess_config.stft.mel_fmax,\n",
    "    center=False,\n",
    ")\n",
    "tacotronSTFT = tacotronSTFT.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the speakers list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import tempfile\n",
    "import base64\n",
    "import soundfile as sf\n",
    "\n",
    "def plot_spectrogram(mel: np.ndarray):\n",
    "    r\"\"\"Plots the mel spectrogram.\"\"\"\n",
    "    plt.figure(dpi=80, figsize=(10, 3))\n",
    "\n",
    "    img = librosa.display.specshow(mel, x_axis=\"time\", y_axis=\"mel\", sr=sample_rate)\n",
    "    plt.title(\"Spectrogram\")\n",
    "    plt.colorbar(img, format=\"%+2.0f dB\")\n",
    "\n",
    "    # Save the plot to a BytesIO object\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format=\"png\")\n",
    "    buf.seek(0)\n",
    "\n",
    "    # Convert the BytesIO object to a base64 string\n",
    "    img_str = base64.b64encode(buf.read()).decode(\"utf-8\")\n",
    "    plt.close()\n",
    "\n",
    "    return img_str\n",
    "\n",
    "def gen_table(text_demo_with_metrics: list):\n",
    "    # Initialize an empty string to store the HTML\n",
    "    html = \"<table border='1'>\"\n",
    "\n",
    "    html += f\"<h4>TTS: </h4> {text_tts}\"\n",
    "\n",
    "    html += \"<h4>Speakers: </h4>\"\n",
    "    html += \"\"\"<tr>\n",
    "        <th>SpeakerID</th>\n",
    "        <th>Speaker Name</th>\n",
    "        <th>Gender</th>\n",
    "        <th>Subset</th>\n",
    "        <th>Audio</th>\n",
    "        <th>InfTime</th>\n",
    "        <th>ermr</th>\n",
    "        <th>jitter</th>\n",
    "        <th>shimmer</th>\n",
    "        <th>spec</th>\n",
    "    </tr>\"\"\"\n",
    "\n",
    "    for row in text_demo_with_metrics:\n",
    "        # Speaker info\n",
    "        speaker_id = row[\"speaker_id\"]\n",
    "        speaker_name = row[\"speaker_name\"]\n",
    "        gender = row[\"gender\"]\n",
    "        subset = row[\"subset\"]\n",
    "        execution_time = row[\"execution_time\"]\n",
    "\n",
    "        # Waveforms and mel spectrogram\n",
    "        wav = row[\"wav\"]\n",
    "        mel = row[\"mel\"]\n",
    "\n",
    "        # Metrics\n",
    "        ermr = row[\"ermr\"]\n",
    "        jitter = row[\"jitter\"]\n",
    "        shimmer = row[\"shimmer\"]\n",
    "\n",
    "        # Round the metrics to 3 decimal places\n",
    "        metrics = [round(x, 3) for x in [ermr, jitter, shimmer]]\n",
    "\n",
    "        # audio = Audio(wav, rate=sample_rate, autoplay=False)\n",
    "\n",
    "        # Save the numpy array to a temporary wav file\n",
    "        with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=True) as wav_file:\n",
    "            sf.write(wav_file.name, wav, sample_rate)\n",
    "\n",
    "            # Convert wav to mp3\n",
    "            audio = AudioSegment.from_wav(wav_file.name)\n",
    "            with tempfile.NamedTemporaryFile(suffix=\".mp3\", delete=True) as mp3_file:\n",
    "                audio.export(mp3_file.name, format=\"mp3\")\n",
    "                mp3_audio = base64.b64encode(mp3_file.read()).decode('utf-8')\n",
    "\n",
    "\n",
    "        # Generate the spectrogram plot\n",
    "        fig = plot_spectrogram(mel)\n",
    "        # <td>{audio._repr_html_()}</td>\n",
    "\n",
    "        # Add a row to the HTML table\n",
    "        html += f\"\"\"<tr>\n",
    "            <td>{speaker_id}</td>\n",
    "            <td>{speaker_name}</td>\n",
    "            <td>{gender}</td>\n",
    "            <td>{subset}</td>\n",
    "            <td><audio controls><source src=\"data:audio/mp3;base64,{mp3_audio}\"></audio></td>\n",
    "            <td>{execution_time}</td>\n",
    "            <td>{metrics[0]}</td>\n",
    "            <td>{metrics[1]}</td>\n",
    "            <td>{metrics[2]}</td>\n",
    "            <td><img src='data:image/png;base64,{fig}' /></td>\n",
    "        </tr>\"\"\"\n",
    "\n",
    "    # Close the HTML table\n",
    "    html += \"</table>\"\n",
    "\n",
    "    return HTML(html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_batch_table(batch: list, batch_idx: int):\n",
    "    df = pd.DataFrame(batch)\n",
    "\n",
    "    # Get the unique cluster labels\n",
    "    df_ermr_sorted = df.sort_values(by=\"ermr\")\n",
    "    metrics = [\"ermr\", \"jitter\", \"shimmer\"]\n",
    "\n",
    "    demo_dirname = f\"logs/{dataset_url}_{checkpoint_name}\"\n",
    "    os.makedirs(demo_dirname, exist_ok=True)\n",
    "\n",
    "    # Add header\n",
    "    result = f\"\"\"\n",
    "    <h3>Chunk #{batch_idx}: </h3>\n",
    "    {df_ermr_sorted[[\"speaker_id\", *metrics]].describe().to_html()}\n",
    "    <h3>Chunk #{batch_idx} audio data: </h3>\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate and display the table for the chunk\n",
    "    # for _, row in df_ermr_sorted.iterrows():\n",
    "    result += gen_table(df_ermr_sorted.to_dict(\"records\")).data # type: ignore\n",
    "\n",
    "    # Save result as HTML\n",
    "    with open(f\"{demo_dirname}/chunk_{batch_idx}.html\", \"w\") as f:\n",
    "        f.write(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_tts = \"\"\"\n",
    "# Casablanca: “But what about us?”\n",
    "# “We’ll always have Paris.”\n",
    "# The Wizard of Oz: “Lions? And Tigers? And Bears?”\n",
    "# “Oh my!”\n",
    "# Star Wars (A New Hope): “He’s almost in range.”\n",
    "# “That’s no moon; it’s a space station.”\n",
    "# Love Story: “Jenny, I’m sorry.”\n",
    "# “Don’t. Love means never having to say you’re sorry.”\n",
    "# No Country for Old Men: “Look, I need to know what I stand to win.”\n",
    "# “Everything.”\n",
    "# Forrest Gump: “I thought I’d try out my sea legs.”\n",
    "# “But you ain’t got no legs, Lieutenant Dan.”\n",
    "# Toy Story: “Buzz, you’re flying!”\n",
    "# “This isn’t flying; this is falling with style.”\n",
    "# As the snake shook its head, a deafening shout behind Harry made both of them jump.\n",
    "# ‘DUDLEY! MR DURSLEY! COME AND LOOK AT THIS SNAKE! YOU WON’T BELIEVE WHAT IT’S DOING!’\n",
    "# \"\"\"\n",
    "\n",
    "text_tts = \"\"\"\n",
    "The Wizard of Oz: “Lions? And Tigers? And Bears?”\n",
    "Toy Story: “Buzz, you’re flying!”\n",
    "As the snake shook its head, a deafening shout behind Harry made both of them jump.\n",
    "‘DUDLEY! MR DURSLEY! COME AND LOOK AT THIS SNAKE! YOU WON’T BELIEVE WHAT IT’S DOING!’\n",
    "\"\"\"\n",
    "\n",
    "with open(\"training/datasets/speaker_id_mapping_libri.json\") as f:\n",
    "    id_mapping = json.load(f)\n",
    "\n",
    "batch_size = 200\n",
    "model.vocoder_module.to(device)\n",
    "\n",
    "metrics = Metrics()\n",
    "text_demo_with_metrics = []\n",
    "\n",
    "speakers_df = pd.read_csv(\n",
    "    \"./datasets_cache/LIBRITTS/LibriTTS/speakers.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    names=[\"READER\", \"GENDER\", \"SUBSET\", \"NAME\"],\n",
    ")\n",
    "\n",
    "subsets = [\"train-clean-100\", \"train-clean-360\", \"train-other-500\"]\n",
    "\n",
    "speakers = speakers_df[speakers_df['SUBSET'].isin(subsets)]\n",
    "\n",
    "start_chunk = 11  # The chunk to start from\n",
    "start_idx = start_chunk * batch_size  # The index to start from\n",
    "\n",
    "for idx, speaker in enumerate(speakers.to_dict(\"records\")):\n",
    "    # Skip the speakers that have already been processed\n",
    "    if idx <= start_idx:\n",
    "        continue\n",
    "\n",
    "    speaker_id = speaker[\"READER\"]\n",
    "    speaker_id = id_mapping.get(str(speaker_id))\n",
    "    speaker_name = speaker[\"NAME\"]\n",
    "    gender = speaker[\"GENDER\"]\n",
    "    subset = speaker[\"SUBSET\"]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        speaker_id_ = torch.tensor([int(speaker_id)], device=device)\n",
    "        start_time = time.time()\n",
    "        wav = model.forward(text_tts, speaker_id_)\n",
    "        end_time = time.time()\n",
    "        (\n",
    "            ermr,\n",
    "            jitter,\n",
    "            shimmer,\n",
    "        ) = metrics.wav_metrics(wav.unsqueeze(0))\n",
    "        execution_time = round(end_time - start_time, 2)\n",
    "\n",
    "        mel = tacotronSTFT.get_mel_from_wav(wav)\n",
    "\n",
    "        text_demo_with_metrics.append({\n",
    "            \"speaker_id\": speaker_id,\n",
    "            \"speaker_name\": speaker_name,\n",
    "            \"gender\": gender,\n",
    "            \"subset\": subset,\n",
    "            \"wav\": wav.detach().cpu().numpy(),\n",
    "            \"execution_time\": execution_time,\n",
    "            \"mel\": mel.detach().cpu().numpy(),\n",
    "            \"ermr\": ermr,\n",
    "            \"jitter\": jitter,\n",
    "            \"shimmer\": shimmer,\n",
    "        })\n",
    "\n",
    "    if idx > 0 and idx % batch_size == 0:\n",
    "        gen_batch_table(text_demo_with_metrics, idx // batch_size)\n",
    "        text_demo_with_metrics = []\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "gen_batch_table(text_demo_with_metrics, 999)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(599, 599)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chunk_1\n",
    "speaker_ids1 = [\n",
    "    32, # US, nan \tM \ttrain-clean-100, min intonation, calm, timbre\n",
    "    130, # BR, \tPeter of Buckinghamshire England \tM \ttrain-other-500, timbre, min intonation, calm, slow\n",
    "    164, # US, \tEd Good \tM \ttrain-other-500, timbre, intonation, warm and calm, good voice\n",
    "    176, # US, \tMicah Sheppard \tM \ttrain-clean-360, intonation, calm\n",
    "    68, # US,\tAlex Buie \tM \ttrain-clean-100,  min intonation, energized\n",
    "    15, # US, \tChip \tM \ttrain-other-500, intonation, interesting voice\n",
    "    145, # US, \tMr. Baby Man \tM \ttrain-clean-360, timbre, intonation, interesting voice\n",
    "    196, # US, \tMike Kauffmann \tM \ttrain-clean-360,  min intonation, average calm\n",
    "    160, # BR,\tdeadwhitemales \tM \ttrain-clean-100, intonation, energized, interesting voice\n",
    "    108, # US, \tKevin McAsh \tM \ttrain-clean-360, min intonation, energized\n",
    "    99, # US, \tStewart Wills \tM \ttrain-clean-100, min intonation, avg energy\n",
    "    50, # US, \tDan Threetrees \tM \ttrain-clean-360, min intonation, avg energy\n",
    "    76, # US, \tML Cohen \tM \ttrain-other-500, intonation, energy, timbre\n",
    "    142, # US, \tMichael Sirois \tM \ttrain-other-500, intonation, energy\n",
    "    95, # US, \tVinny Bove \tM \ttrain-clean-360, intonation, energy, timbre\n",
    "    169, # US, \tRichard Grove \tM \ttrain-other-500, intonation, energy\n",
    "    147, # US, \tEileen George \tF \ttrain-clean-360, intonation, calm\n",
    "    92, # BR \tvlooi \tF \ttrain-other-500 teenager voice, intonation, energized\n",
    "    117, # US, \tCaitlin Kelly \tF \ttrain-clean-360, intonation, energized, interesting voice\n",
    "    89, # US, \tPaula Berinstein \tF \ttrain-clean-360, min intonation, energized\n",
    "    182, # US \tKaty Preston \tF \ttrain-other-500, intonation, energized\n",
    "    105, # US \tMarian Brown \tF \ttrain-clean-360, min intonation, energized, timbre, quality GOOD\n",
    "    11, # BR \tLinton \tF \ttrain-other-500, min intonation, calm\n",
    "    18, # US \tSherry Crowther \tF \ttrain-clean-100, intonation, energized, timbre\n",
    "    38, # US \tKurt Copeland \tM \ttrain-clean-360, intonation, energized\n",
    "    52, # US, \tCori Samuel \tF \ttrain-other-500, intonation, energized, timbre\n",
    "    21, # US, \tKelly Bescherer \tF \ttrain-other-500, intonation, energized, timbre\n",
    "    48, # US, \tRosalind Wills \tF \ttrain-clean-100, intonation, timbre, poor quality, but interesting voice\n",
    "    63, # US, \tLinda Wilcox \tF \ttrain-other-500, very poor quality, but VERY interesting intonation\n",
    "    45, # US, \tCatharine Eastman \tF \ttrain-clean-100, very quality, interesting intonation\n",
    "    193, # US, \tNomenphile \tF \ttrain-other-500, avg quality, intonation\n",
    "    207, # US \tSage Tyrtle \tF \ttrain-other-500, avg quality, interesting intonation and timbre\n",
    "    73, # US \tClaire Goget \tF \ttrain-clean-100, avg quality, intonation\n",
    "    42, # US \tJennifer Crispin \tF \ttrain-clean-360, quality, calm\n",
    "    113, # US \tAlice Elizabeth Still \tF \ttrain-other-500, avg quality, intonation\n",
    "    49, # US \tKristen McQuillin \tF \ttrain-clean-100, avg quality, interesting intonation and timbre\n",
    "    185, # US\tKim Braun \tF \ttrain-clean-360, avg quality, avg intonation, but interesting timbre\n",
    "    165, # US \tElisabeth Shields \tF \ttrain-clean-100, avg quality, interesting intonation, timbre\n",
    "    36, # US \tchriss the girl \tF \ttrain-other-500, interesting intonation, timbre\n",
    "    96, # US \tKymm Zuckert \tF \ttrain-other-500, avg quality, interesting intonation, timbre of middle age wooman\n",
    "    102, # US \tMaureen S. O'Brien \tF \ttrain-clean-100, avg quality, interesting intonation\n",
    "    64, # US \tChristiane Levesque \tF \ttrain-clean-360, young voice, calm\n",
    "    30, # BR, \tOphelia Darcy \tF \ttrain-other-500, avg quality, intonation\n",
    "    0, # US \tKristin LeMoine \tF \ttrain-clean-360, avg quality, intonation, fast-speaker\n",
    "    192, # US, \tNocturna \tF \ttrain-clean-100, avg quality, intonation\n",
    "    146, # US \tJim Cadwell \tM \ttrain-other-500, avg quality, intonation\n",
    "    80, # US\tFox in the Stars \tF \ttrain-clean-100, avg quality, intonation\n",
    "    162, # BR\tMike Gardom \tM \ttrain-other-500, avg quality, intonation, timbre\n",
    "    66, # US \tMaddie \tF \ttrain-clean-360, intonation, timbre\n",
    "    124, # US \tSteve Karafit \tM \ttrain-clean-100, poor quality, intonation, timbre, COOL\n",
    "    123, # US \tSean McGaughey \tM \ttrain-clean-360, poor quality, intonation, timbre\n",
    "    55, # US, \tPatricia Oakley \tF \ttrain-clean-360, intonation, timbre\n",
    "    91, # BR \tChris Goringe \tM \ttrain-other-500, intonation, timbre\n",
    "    171, # US\tPaul Harvey \tM \ttrain-clean-360, avg quality, intonation, timbre\n",
    "    61, # US\tJohn Greenman \tM \ttrain-other-500, intonation, timbre\n",
    "    122,  # US  carnright \tM \ttrain-clean-100, avg intonation, timbre\n",
    "    82, # BR \tAndy Minter \tM \ttrain-other-500, intonation, GOOD timbre,\n",
    "    118, # US \tBrenda Dayne \tF \ttrain-clean-360, timbre, calm\n",
    "    106, # US\tMark F. Smith \tM \ttrain-clean-360, GOOD timbre, interesting intonation\n",
    "    187, # US\tLenny Glionna Jr. \tM \ttrain-other-500, intonation, timbre\n",
    "    158, # US \tRandy Phillips \tM \ttrain-clean-100, avg intonation, timbre\n",
    "    83, # US\tGraham Williams \tM \ttrain-other-500, intonation, timbre\n",
    "    181, # BR \tJon Ingram \tM \ttrain-other-500, intonation, timbre\n",
    "    8, # US\tDenny Sayers \tM \ttrain-clean-100, timbre\n",
    "    205, # US\tRobert Garrison \tM \ttrain-clean-360, timbre, interesting intonation\n",
    "    172, # US \tHarvey Chinn \tM \ttrain-other-500, great timbre, intonation\n",
    "]\n",
    "# chunk_2\n",
    "speaker_ids2 = [\n",
    "    305, # US \tMichael Crowl \tM \ttrain-clean-360, timbre, intonation\n",
    "    417, # US\tKiki Baessell \tF \ttrain-clean-360, timbre, intonation\n",
    "    241, # US\tJean O'Sullivan \tF \ttrain-clean-360, timbre, intonation\n",
    "    412, # US\tNichole Karl \tF \ttrain-other-500, timbre\n",
    "    294, # US\tDiana Kiesners \tF \ttrain-clean-360, timbre, intonation\n",
    "    414, # US \tChristabel \tF \ttrain-clean-100, great and calm timbre\n",
    "    251, # US\tAaron Benedict \tM \ttrain-other-500, timbre, intonation\n",
    "    218, # US\tJoy Chan \tF \ttrain-other-500, timbre, intonation, quality\n",
    "    259, # BR\tmiette \tF \ttrain-other-500, timbre, intonatio\n",
    "    275, # US\tZale Schafer (Rose May Chamberlin Memorial Foundat \tF \ttrain-clean-360, timbre, intonation\n",
    "    368, # US\tSusie G. \tF \ttrain-other-500, teenage voice, timbre, intonation\n",
    "    327, # BR\tmjd-s \tF \ttrain-other-500, timbre, intonation\n",
    "    366, # US \tpattymarie \tF \ttrain-clean-360, calm, timbre\n",
    "    399, # US\tentada \tF \ttrain-clean-360, timbre, intonation\n",
    "    273, # BR \tAndrew Lebrun \tM \ttrain-other-500, timbre, intonation\n",
    "    352, # US \tMur Lafferty \tF \ttrain-clean-360, timbre, enery, young voice\n",
    "    283, # US\tBethany Simpson \tF \ttrain-clean-360, timbre, intonation\n",
    "    248, # BR \tfieldsofgold \tM \ttrain-other-500, timbre, intonation\n",
    "    372, # US\tJim Mullins \tM \ttrain-clean-360, timbre, intonation, quality\n",
    "    250, # US\tQuentin \tM \ttrain-clean-360, unique timbre, intonation, quality\n",
    "    403, # US\tIgor Teaforay \tF \ttrain-clean-360, timbre, avg intonation\n",
    "    375, # US\tiscatel \tM \ttrain-clean-360, unique timbre, avg intonation\n",
    "    355, # US \tLana Taylor \tF \ttrain-clean-100, unique timbre, intonation\n",
    "    220, # US\tTina Tilney \tF \ttrain-clean-360, unique timbre, high intonation\n",
    "    392, # US \tBrooks Jensen \tM \ttrain-clean-360, timbre, avg speed, avg intonation\n",
    "    255, # US \tCaroline Mercier \tF \ttrain-clean-360, timbre, avg speed, intonation\n",
    "    292, # US \tTamara R. Schwartz \tF \ttrain-clean-100, timbre, avg speed, intonation\n",
    "    258, # US \tRuss Maxwell \tM \ttrain-clean-360, timbre, intonation, unique voice\n",
    "    233, # US\tmikenkat \tM \ttrain-clean-360, timbre, intonation\n",
    "    394, # US \tswroot \tF \ttrain-clean-360, timbre, intonation, unique voice, good quality\n",
    "    382, # US\tKelli Robinson \tF \ttrain-clean-360, timbre, intonation, avg quality\n",
    "    322, # US\tMitchell Dwyer \tM \ttrain-clean-360, timbre, intonation, avg quality, unique voice\n",
    "    285, # US\tkoijmonop \tM \ttrain-clean-360, timbre, intonation, avg quality, unique voice\n",
    "    290, # US\tJ. M. Smallheer \tF \ttrain-clean-360, timbre, intonation, avg quality\n",
    "    383, # US\tMike Roop \tM \ttrain-other-500, timbre, intonation, quality, unique voice\n",
    "    263, # US \tEric S. Piotrowski \tM \ttrain-clean-360, timbre, intonation, avg quality\n",
    "    373, # BR\tBrooks Seveer \tM \ttrain-clean-360, timbre, intonation, avg quality, unique voice\n",
    "    340, # US\tNick Gallant \tM \ttrain-clean-100, unique timbre\n",
    "    331, # BR \tLuke Venediger \tM \ttrain-other-500, timbre, intonation\n",
    "    234, # BR\tMenno \tM \ttrain-other-500, timbre, intonation, unique voice\n",
    "    398, # BR \tSam Fold \tM \ttrain-other-500, timbre, intonation\n",
    "    254, # BR\tRebecca Dittman \tM \ttrain-other-500, timbre, intonation\n",
    "    264, # US\tKentF \tM \ttrain-clean-360, timbre, intonation\n",
    "    214, # US \tScott Splavec \tM \ttrain-clean-100, timbre, intonation\n",
    "    359, # BR\tGreg Bryant \tM \ttrain-clean-100, timbre, intonation\n",
    "    253, # US\tFrank \tM \ttrain-other-500, timbre, intonation\n",
    "    249, # US\tBill Stackpole \tM \ttrain-clean-360, timbre, intonation\n",
    "    236, # US\tMatthew Shepherd \tM \ttrain-clean-360, timbre, intonation, unique voice\n",
    "    390, # US\tJimmyLogan \tM \ttrain-clean-360, avg intonation, timbre\n",
    "    216, # US\tDave Ranson \tM \ttrain-clean-100, unique voice, timbre, intonation\n",
    "    215, # US\tMark Bradford \tM \ttrain-clean-360, timbre, intonation\n",
    "    212, # US\tGlen Hallstrom \tM \ttrain-other-500, timbre, intonation\n",
    "    314, # US\tCarl Vonnoh, III \tM \ttrain-clean-360, unique voice, timbre, intonation\n",
    "    347, # US\tAnadaxis_Canejia \tM \ttrain-other-500, unique voice, timbre, intonation, good quality\n",
    "    330, # US\tAaron Andradne \tM \ttrain-clean-360, timbre, intonation\n",
    "    393, # US\tTim Lundeen \tM \ttrain-clean-360, timbre, intonation\n",
    "    40,  # BR \tJustin Brett \tM \ttrain-other-500, unique voice, timbre, intonation, good quality\n",
    "    386, # US \tMichael Kirkpatrick \tM \ttrain-clean-360, unique intonation, timbre\n",
    "    315, # US\tJean Crevier \tM \ttrain-other-500, unique intonation, timbre\n",
    "    349, # US\tbrenthumphries \tM \ttrain-other-500, unique timbre, min intonation\n",
    "    242, # US\tJ. Hall \tM \ttrain-other-500, unique timbre, intonation\n",
    "    308, # US\tEric Connover \tM \ttrain-other-500, timbre, intonation\n",
    "    313, # BR\tTim Bulkeley \tM \ttrain-other-500, timbre, intonation\n",
    "    334, # US\tmawrtea \tM \ttrain-clean-360, unique voice, timbre, intonation\n",
    "]\n",
    "# chunk_3\n",
    "speaker_ids3 = [\n",
    "    469, # US \tChristian Pecaut \tM \ttrain-clean-360, clear voice, min intonation\n",
    "    601, # BR\tJonathan Horniblow \tM \ttrain-other-500, clear voice, min intonation\n",
    "    482, # US\tEstragon \tM \ttrain-clean-360, clear voice, min intonation\n",
    "    580, # US\tKyle M. \tM \ttrain-clean-360, clear voice, min intonation, timbre\n",
    "    463, # US\tChris Hughes \tM \ttrain-other-500, clear voice, min intonation, timbre, energized\n",
    "    472, # BR\tTim Makarios \tM \ttrain-other-500, min intonation\n",
    "    536, # US\tRobert Flach \tM \ttrain-other-500, intonation, timbre, unique voice\n",
    "    569, # US \tArouet \tM \ttrain-clean-360, avg intonation, timbre\n",
    "    523, # US\tMichael Loftus \tM \ttrain-clean-360, avg intonation, timbre\n",
    "    454, # US\tTim Gregory \tM \ttrain-clean-100, avg intonation\n",
    "    425, # US\tRedToby \tM \ttrain-clean-360, avg intonation, timbre, unique voice\n",
    "    574, # US\tDaniel Shorten \tM \ttrain-clean-100, avg intonation, timbre, clear voice\n",
    "    465, # US \tLeonie Rose \tF \ttrain-clean-100, avg intonation, timbre\n",
    "    481, # US \tScott Sherris \tM \ttrain-clean-360, intonation, timbre\n",
    "    531, # US \tFr. Richard Zeile of Detroit \tM \ttrain-other-500, intonation, timbre, unique voice\n",
    "    628, # US\tBryan Ness \tM \ttrain-clean-100, intonation, timbre, unique voice\n",
    "    427, # US \tJohn Lieder \tM \ttrain-clean-360, intonation, timbre\n",
    "    527, # US\tJason Isbell \tM or F \ttrain-clean-360, intonation, timbre\n",
    "    468, # US\tJenilee \tF \ttrain-other-500, energized, young voice, intonation\n",
    "    441, # US\troolynninms \tF \ttrain-clean-100, energized, intonation\n",
    "    430, # BR \tMillbeach \tF \ttrain-other-500, intonation, timbre\n",
    "    498, # US\tChris Gladis \tM \ttrain-clean-100, intonation, timbre\n",
    "    435, # US \tDebra Lynn \tF \ttrain-other-500, intonation, timbre\n",
    "    499, # US \tTammy Sanders \tF \ttrain-clean-100, intonation, timbre, unique voice\n",
    "    429, # US \tGiles Baker \tM \ttrain-other-500, timbre\n",
    "    495, # US\tJanet Friday \tF \ttrain-clean-360, INTONATION, timbre\n",
    "    456, # US\tCatherine Fitz \tF \ttrain-clean-360, timbre\n",
    "    617, # US \tPJ \tF \ttrain-other-500, timbre\n",
    "    445, # US\tJennette Selig \tF \ttrain-clean-360, intonation, timbre\n",
    "    552, # US\tMim Ritty \tF \ttrain-clean-100, intonation, timbre\n",
    "    561, # US\tLorelle Anderson \tF \ttrain-clean-100, intonation, timbre, quality\n",
    "    447, # US\tLee Ann Howlett \tF \ttrain-clean-360, intonation, timbre, quality\n",
    "    604, # BR\tAnne-Marie \tF \ttrain-other-500, intonation, timbre\n",
    "    450, # US\tHeather Duncan \tF \ttrain-clean-360, intonation, unique voice\n",
    "    502, # US\tLee Elliott \tF \ttrain-other-500, intonation\n",
    "    517, # US\tMadame Tusk \tF \ttrain-other-500, intonation\n",
    "    605, # BR\tClassicsfan \tF \ttrain-other-500, intonation, unique voice, timbre\n",
    "    426, # US\tMegan Stemm-Wade \tF \ttrain-clean-100, clear voice, min intonation\n",
    "    544, # US\tMiranda Stinson \tF \ttrain-clean-360, unique voice\n",
    "    568, # US\tMichael Yourshaw \tM \ttrain-other-500, clear voice\n",
    "    588, # US\tKalynda \tF \ttrain-clean-360, clear voice, timbre\n",
    "    477, # US\tPatti Brugman \tF \ttrain-other-500, clear voice\n",
    "    607, # BR \tSteph \tF \ttrain-other-500, clear voice\n",
    "    479, # US \tWina Hathaway \tF \ttrain-other-500, intonation, timbre\n",
    "    618, # US\tLinnea \tF \ttrain-other-500, timbre\n",
    "    549, # US\tAmyAG \tF \ttrain-other-500, teenager voice\n",
    "    596, # US\tJo \tF \ttrain-other-500, timbre, min intonation\n",
    "]\n",
    "# chunk 4\n",
    "speaker_ids4 = [\n",
    "    770, # US\tPete Williams, Pittsburgh, PA \tM \ttrain-clean-360, clear, calm voice\n",
    "    730, # US\tNick Gisburne \tM \ttrain-other-500, clear, calm voice\n",
    "    680, # US\tKevin Kivikko \tM \ttrain-clean-360, min intonation, calm voice, timbre\n",
    "    791, # US\tDavid Kleparek \tM \ttrain-clean-100, clear, calm voice\n",
    "    800, # US\tJack Farrell \tM \ttrain-clean-360, clear, calm voice, good low tone\n",
    "    839, # BR\tBen Dutton \tM \ttrain-other-500, clear, calm voice, min intonation\n",
    "    661, # US\tJames Gladwin \tM \ttrain-other-500, calm voice, min intonation\n",
    "    648, # US\tMuhammad Mussnoon \tM \ttrain-other-500, timbre\n",
    "    798, # US\tWyatt \tM \ttrain-other-50, calm voice, timbre, avg intonation\n",
    "    699, # US\tMichael Macedonia \tM \ttrain-clean-360, calm voice, timbre\n",
    "    757, # US\tRoger Melin \tM \ttrain-clean-360, timbre, avg intonation, unique voice\n",
    "    782, # US\tAlec Daitsman \tM \ttrain-clean-360, timbre, avg intonation\n",
    "    816, # US\tMichael Bradford \tM \ttrain-clean-360, timbre, avg intonation, teenager voice\n",
    "    846, # US\tGayland Darnell \tM \ttrain-clean-360, senior voice, timbre, avg intonation\n",
    "    831, # US\tDavid Federman \tM \ttrain-other-500, timbre, avg intonation\n",
    "    817, # US\ttexttalker \tM \ttrain-clean-360, timbre, avg intonation\n",
    "    819, # US\tn8evv \tM \ttrain-clean-360, timbre, intonation\n",
    "    672, # BR\tStuart Bell \tM \ttrain-other-500, timbre, intonation, clear voice\n",
    "    837, # US\tjohnb \tM \ttrain-other-500, timbre, intonation\n",
    "    775, # US\tRalph Volpi \tM \ttrain-clean-360, senior voice, timbre, intonation\n",
    "    685, # US\tNikki Sullivan \tF \ttrain-clean-100, clear voice, avg intonation, timbre\n",
    "    666, # US\tKelly Dougherty \tM \ttrain-clean-360, clear voice, avg intonation, timbre\n",
    "    809, # US\tAnna-Maria Viola \tF \ttrain-clean-360, timbre, avg intonation\n",
    "    640, # US\tDavid A. Stokely \tM \ttrain-other-500, emotional, timbre, intonation, unique voice\n",
    "    818, # US\tMatt Warzel \tF \ttrain-clean-360, timbre, intonation\n",
    "    711, # US\tJulie Bynum \tF \ttrain-clean-360, senior voice, timbre, min intonation\n",
    "    766, # US\tClive Catterall \tM \ttrain-other-500, avg intonation, timbre\n",
    "    649, # US\tScarlett! \tF \ttrain-clean-360, intonation, timbre\n",
    "    732, # US\tTysto \tM/F\ttrain-clean-360, intonation, timbre\n",
    "    769, # US, Alan Brown \tM \ttrain-other-500, avg intonation, timbre\n",
    "    677, # US\tAllyson Hester \tF \ttrain-other-500, intonation, timbre, unique voice\n",
    "    833, # US\tAlana Jordan \tF \ttrain-clean-360, intonation, timbre\n",
    "    676, # US\tJennifer \tF \ttrain-clean-100, intonation, timbre\n",
    "    710, # US\tSheila Morton \tF \ttrain-clean-100, intonation, timbre, unique voice\n",
    "    645, # US\tMicah \tF \ttrain-other-500, intonation, timbre, unique voice, teenager voice\n",
    "    771, # US\tIsosceles \tF \ttrain-clean-360, intonation, timbre\n",
    "    636, # US\tMatthew Howell \tF \ttrain-other-500, timbre, avg intonation\n",
    "    822, # US\tkristiface \tF \ttrain-clean-360, timbre, intonation, unique voice\n",
    "    830, # US\tmusici123 \tF \ttrain-other-500, timbre, intonation, unique voice\n",
    "    657, # US\tShannon \tF \ttrain-other-500, timbre, intonation\n",
    "    797, # US\tChris Jones \tF \ttrain-other-500, timbre, intonation, calm voice\n",
    "    835, # BR\tRachel Lintern \tF \ttrain-other-500, timbre, intonation\n",
    "    761, # US\tSusan Umpleby \tF \ttrain-clean-100, timbre, intonation, unique voice\n",
    "    653, # US\tcucciasv \tF \ttrain-other-500, timbre, avg intonation\n",
    "    751, # US\tRalph Snelson \tM \ttrain-other-500, timbre, avg intonation, unique voice\n",
    "    848, # BR\tsenshisteph \tF \ttrain-other-500, timbre, intonation\n",
    "    808, # US\tM. J. Boyle \tF \ttrain-other-500, timbre, intonation, senior voice\n",
    "    840, # US\tB. Grebe \tF \ttrain-clean-360, timbre, intonation, unique voice\n",
    "    742, # US\tKatherine Holt \tF \ttrain-other-500, timbre, intonation\n",
    "    834, # US\tSerin \tF \ttrain-other-500, unique voice\n",
    "    668, # US\tJan Baxter \tF \ttrain-clean-360, intoantion, timbre, calm voice\n",
    "    752, # US\tCat Schirf \tF \ttrain-other-500, intoantion, timbre\n",
    "    641, # US\tEliza Horne \tF \ttrain-other-500, intoantion, timbre\n",
    "    644, # US\tCynthia Zocca \tF \ttrain-clean-360, intoantion, timbre\n",
    "    781, # US\tMegan Kunkel \tF \ttrain-other-500, intoantion, timbre, teenager voice\n",
    "    727, # US\tJodi Krangle \tF \ttrain-clean-360, timbre\n",
    "    719, # US\tCharlene V. Smith \tF \ttrain-other-500, intoantion, timbre\n",
    "    804, # BR\tFirstKnight \tF \ttrain-other-500, unique voice, intoantion, timbre\n",
    "    675, # US\tinkwelldragon \tF \ttrain-clean-360, intoantion, timbre\n",
    "    697, # US\tJennie Hughes \tF \ttrain-other-500, timbre\n",
    "    731, # IND\tPriya, India \tF \ttrain-other-500, avg intoantion, timbre\n",
    "    741, # US \tNick Marsh \tM \ttrain-other-500, intoantion, timbre, old man voice, unique voice\n",
    "]\n",
    "# chunk 5\n",
    "speaker_ids5 = [\n",
    "    922,  # ricell\n",
    "    1000,  # artos\n",
    "    1007,  # Mike Conrad\n",
    "    858,  # Scott Merrill\n",
    "    943,  # Matthew C. Heckel\n",
    "    984,  # woggy298\n",
    "    936,  # BUAES\n",
    "    935,  # Topaz\n",
    "    977,  # Logan McCamon\n",
    "    946,  # Cantor\n",
    "    1030,  # Ancient mariner\n",
    "    1046,  # Preston McConkie\n",
    "    1022,  # peac\n",
    "    908,  # Quentin Manuel\n",
    "    924,  # Andrew Coleman\n",
    "    964,  # Utek\n",
    "    950,  # davechase\n",
    "    1020,  # nihilist00\n",
    "    1043,  # B. G. Oxford\n",
    "    881,  # mpetranech\n",
    "    852,  # Steven Proctor\n",
    "    995,  # Parrot\n",
    "    1045,  # joi\n",
    "    1048,  # tornadogrrrl\n",
    "    900,  # peaceuntoyou\n",
    "    932,  # Raerity\n",
    "    1005,  # Beatrice\n",
    "    851,  # Jennifer Lott\n",
    "    897,  # Jan Dawn Doronila\n",
    "    1041,  # mjbrichant\n",
    "    863,  # K Hindall\n",
    "    937,  # Sarah Gutierrez\n",
    "    1049,  # Diana Solomon\n",
    "    1001,  # TriciaG\n",
    "    934,  # Darla\n",
    "    947,  # Larissa Little\n",
    "    944,  # Sarafina Suransky\n",
    "    870,  # Barbara Bulkeley\n",
    "    923,  # Jane Greensmith\n",
    "    1047,  # Hannah Dowell\n",
    "    967,  # Stephanie Land\n",
    "    929,  # Petra\n",
    "    963,  # MichelleHarris\n",
    "    891,  # anoldfashiongirl\n",
    "    890,  # PopularOutcast\n",
    "    992,  # Fran\n",
    "]\n",
    "# chunk_6\n",
    "speaker_ids6 = [\n",
    "    1143, #\tKeith Henige \tM \ttrain-other-500\n",
    "    1159, #\tMatt Wills \tM \ttrain-clean-360\n",
    "    1127, #\tC.J. Casey \tM \ttrain-other-500\n",
    "    1235, #\tRichard Kilmer \tM \ttrain-other-500\n",
    "    1092, #\tBenW \tM \ttrain-other-500\n",
    "    1270, # Brendan Tannam \tM \ttrain-other-500\n",
    "    1214, #\tDavid Baldwin \tM \ttrain-clean-360\n",
    "    1255, #\tDaniel Paashaus \tM \ttrain-other-500\n",
    "    1152, #\tBrian Keith Barnes \tM \ttrain-clean-360\n",
    "    1158, #\tStarrDog \tM \ttrain-other-500\n",
    "    1256, #\tGraeme Dunlop \tM \ttrain-other-500\n",
    "    1215, #\tKevin Maxson \tM \ttrain-clean-360\n",
    "    1274, #\tJud Niven \tM \ttrain-clean-360\n",
    "    1168, #\tEpistomolus \tM \ttrain-clean-100\n",
    "    1089, #\tBill Ruhsam \tM \ttrain-clean-360\n",
    "    1142, #\tJonathan Burchard \tM \ttrain-other-500\n",
    "    1090, #\tTermin Dyan \tM \ttrain-other-500\n",
    "    1109, #\tMartin Geeson \tM \ttrain-other-500\n",
    "    1230, #\tTroy Bond \tM \ttrain-other-500\n",
    "    1150, #\tTexasSteve \tM \ttrain-other-500\n",
    "    1191, # Denise Lacey \tF \ttrain-other-500\n",
    "    1259, # \tMegan Argo \tF \ttrain-other-500\n",
    "    1238, #\tmadmouth \tF \ttrain-other-500\n",
    "    1135, #\tLinda Andrus \tF \ttrain-clean-360\n",
    "    1247, #\tSarah LuAnn \tF \ttrain-clean-100\n",
    "    1115, #\tRachel Gatwood \tF \ttrain-clean-360\n",
    "    1065, #\tBob Sherman \tM \ttrain-other-500\n",
    "    1204, #\tDale A. Bade \tF \ttrain-clean-360\n",
    "    1174, #\tFrances Marcinkiewicz \tF \ttrain-\n",
    "    1257, #\tAvaille \tF \ttrain-other-500\n",
    "    1239, #\tRachell Lovett \tF \ttrain-clean-360\n",
    "    1273, #\tgmiteva \tF \ttrain-other-500\n",
    "    1242, #\tRichard Ellwood \tM \ttrain-clean-360\n",
    "    1093, #\tKatie Riley \tF \ttrain-clean-360\n",
    "    1063, # \tSuD \tF \ttrain-other-500\n",
    "    1098, #\tKerry Hiles \tF \ttrain-other-500\n",
    "    1254, #\tRosie \tF \ttrain-clean-100\n",
    "    1157, # \tBev J Stevens \tF \ttrain-clean-360\n",
    "    1184, #\tJoseph Couves \tF \ttrain-other-500\n",
    "    1253, #\tCaroline Shapiro \tF \ttrain-other-500\n",
    "    1183, #\tEvelyn Clarke \tF \ttrain-other-500\n",
    "    1082, #\tSymmie \tF \ttrain-clean-360\n",
    "    1128, #\tLinda Ferguson \tF \ttrain-other-500\n",
    "    1108, #\tPaul McCartan \tM \ttrain-other-500\n",
    "    1202, #\tJoy Easton \tF \ttrain-clean-360\n",
    "    1226, #\tserenitylee \tF \ttrain-clean-360\n",
    "    1105, #\tBridget Gaige \tF \ttrain-clean-360\n",
    "    1229, #\tRoseA \tF \ttrain-clean-360\n",
    "    1181, #\tJ. Rebecca Franklin \tF \ttrain-clean-360\n",
    "    1231, #\tAbigail Bartels \tF \ttrain-other-500\n",
    "    1182, #\ttabithat \tF \ttrain-other-500\n",
    "    1217, #\tJimOCR \tM \ttrain-other-500\n",
    "    1171, #\tRoberta Carlisle \tF \ttrain-other-500\n",
    "    1268, #\tA. Janelle Risa \tF \ttrain-clean-100\n",
    "    1243, #\tRachel P. \tF \ttrain-clean-360\n",
    "    1071, #\tjs392 \tF \ttrain-other-500\n",
    "]\n",
    "# chunk_7\n",
    "speaker_ids7 = [\n",
    "    1428,  # Gary Dzierlenga\n",
    "    1315,  # John Dennison\n",
    "    1376,  # mevans\n",
    "    1330,  # William Peck\n",
    "    1400,  # scrawl\n",
    "    1314,  # Michael Wolf\n",
    "    1425,  # Jonah Cummings\n",
    "    1438,  # Tom Barron\n",
    "    1281,  # garbageman99\n",
    "    1414,  # Preston Scrape\n",
    "    1375,  # Frank Adams\n",
    "    1410,  # Zachary Johnson\n",
    "    1365,  # Eric Leach\n",
    "    1302,  # davidb\n",
    "    1354,  # Kristen Zaza\n",
    "    1346,  # Jeanie\n",
    "    1320,  # Anita Fleming\n",
    "    1370,  # Savanna Herrold\n",
    "    1290,  # Veronica Jenkins\n",
    "    1437,  # Charles RUHE\n",
    "    1297,  # May Low\n",
    "    1440,  # P Moscato\n",
    "    1433,  # browneyedgirl32382\n",
    "    1366,  # cher0520\n",
    "    1285,  # Ric F\n",
    "    1399,  # Jeanne Luft\n",
    "    1402,  # Angel5\n",
    "    1303,  # kiwafruit\n",
    "    1301,  # Barbara Clements\n",
    "    1453,  # Anna-Lisa Ott\n",
    "    1374,  # pachayes\n",
    "    1373,  # Maria Therese\n",
    "]\n",
    "# chunk 8\n",
    "speaker_ids8 = [\n",
    "    1649,  # Phineas Redux\n",
    "    1691,  # sparks0314\n",
    "    1672,  # Mike Wajda\n",
    "    1539,  # Nathan Jordan\n",
    "    1610,  # jgoffena\n",
    "    1512,  # Matt Soar\n",
    "    1526,  # Mike Harris\n",
    "    1647,  # Patrick Reinhart\n",
    "    1636,  # jessecoy\n",
    "    1676,  # Gargoyle\n",
    "    1595,  # Matthew Reece\n",
    "    1609,  # Jacob Paul Starr\n",
    "    1671,  # bobbybrill\n",
    "    1555,  # Andrew Nelson\n",
    "    1657,  # alwpoe\n",
    "    1592,  # jerryB\n",
    "    1505,  # Rom Maczka\n",
    "    1565,  # bryan.peterson\n",
    "    1644,  # Christopher Maust\n",
    "    1695,  # Tina Nuzzi\n",
    "    1702,  # Sirmelja\n",
    "    1697,  # Lonelle Yoder\n",
    "    1596,  # Joyce Couch\n",
    "    1660,  # Jerry Romero\n",
    "    1524,  # Elizabeth Barr\n",
    "    1643,  # Linette Geisel\n",
    "    1543,  # Lauren McCullough\n",
    "    1613,  # Elsa Youngsteadt\n",
    "    1662,  # GabrielleC\n",
    "    1587,  # Claudia Wilson\n",
    "    1641,  # Kirsten Wever\n",
    "    1614,  # Jennifer Dionne\n",
    "    1603,  # Christine Rodriguez\n",
    "    1546,  # Carrie Heyes\n",
    "    1579,  # Linda Velwest\n",
    "    1638,  # Laura Victoria\n",
    "    1651,  # Debbie Pieterse\n",
    "    1554,  # Natalie Sullivan\n",
    "    1656,  # Sharon Omi\n",
    "    1607,  # Lynda Sizemore\n",
    "    1670,  # dmbrought\n",
    "    1659,  # kelleywyskiel\n",
    "]\n",
    "# chunk_9\n",
    "speaker_ids9 = [\n",
    "    1785, # BR\tTRUEBRIT \tM \ttrain-other-500, timbre, min intonation\n",
    "    1776, # US\tdan_h \tM \ttrain-other-500, avg intoantion, timbre\n",
    "    1791, # US\tDavid Cummings \tM \ttrain-clean-360, avg intoantion, timbre\n",
    "    1707, # US \tDavid Olson \tM \ttrain-other-500, unique voice, intoantion, timbre\n",
    "    1801, # US\tJohn O \tM \ttrain-other-500, unique voice, min intoantion, timbre\n",
    "    1903, # US\tstephenreader \tM \ttrain-other-500, velvet unique voice\n",
    "    1856, # BR\tCraig Gulliver \tM \ttrain-other-500, avg intoantion, timbre\n",
    "    1906, # US\tTony Russell \tM \ttrain-clean-360, dictor voice, avg intoantion, timbre\n",
    "    1806, # US\tMarc Pizzuti \tM \ttrain-other-500, avg intoantion\n",
    "    1828, # US\tDavid Wales \tM \ttrain-clean-100, avg intoantion, timbre\n",
    "    1849, # US\tFred DeBerardinis \tM \ttrain-clean-100, avg intoantion, timbre, unique voice\n",
    "    1712, # BR\tSteve Belleguelle \tM \ttrain-other-500, avg intoantion, timbre\n",
    "    1853, # US\tRon Altman \tM \ttrain-other-500, intoantion, unique voice, timbre\n",
    "    1805, # US\tVince Dee \tM \ttrain-clean-100, unique voice, timbre\n",
    "    1838, # US\tMorey Kunin \tM \ttrain-clean-360, young voice, intoantion, timbre\n",
    "    1862, # US Alexandre Laplante \tM \ttrain-clean-360, young voice, intoantion, timbre\n",
    "    1915, # US\tT.E. McHenry \tM \ttrain-other-500, unique voice, dictor voice, intoantion, timbre\n",
    "    1772, # US\thaggisreflux \tM \ttrain-clean-360, intoantion, timbre\n",
    "    1831, # BR\tNigel Boydell \tM \ttrain-other-500, unique voice, intoantion, timbre\n",
    "    1706, # BR\tDeborah Knight \tF \ttrain-clean-100, unique voice, intoantion, timbre\n",
    "    1908, # US\tfshort \tF \ttrain-other-500\n",
    "    1783, # US\tSarah Crampton \tF \ttrain-clean-360\n",
    "    1781, # US\thumanode \tM \ttrain-clean-360, unique voice\n",
    "    1779, # US\tWendy Almeida \tF \ttrain-clean-360\n",
    "    1839, # US\tJames E. Carson \tM \ttrain-clean-360\n",
    "    1724, # US\tJuliana M. \tF \ttrain-clean-360\n",
    "    1728, # US\tVinnie Tesla \tM \ttrain-clean-360\n",
    "    1907, # US\tSnapdragon \tF \ttrain-other-500\n",
    "    1881, # US\tJulienne \tF \ttrain-other-500\n",
    "    1802, # US\tselway \tF \ttrain-other-500\n",
    "    1826, # US\tJohn Hoerr \tM \ttrain-clean-100\n",
    "    1725, # BR\tRuth Kidson \tF \ttrain-other-500\n",
    "    1764, # US\tReadWriteLib \tF \ttrain-clean-360\n",
    "    1794, # US\tMichelle Remington \tF \ttrain-clean-360\n",
    "    1880, # US\tChristine Nendza \tF \ttrain-clean-360\n",
    "    1848, # US\tMonica Knuppe \tF \ttrain-clean-360\n",
    "    1736, # US\tSpike Holcomb \tF \ttrain-other-500\n",
    "    1841, # US\tElena \tF \ttrain-clean-360\n",
    "    1836, # US\tKendall Ashyby \tF \ttrain-other-500\n",
    "    1741, # US\tanjieliu \tF \ttrain-other-500\n",
    "    1803, # US\tSusan Hanfield \tF \ttrain-clean-360\n",
    "    1761, # US\tEliMarieHK \tF \ttrain-other-500\n",
    "    1745, # US\tJanet \tF \ttrain-clean-360\n",
    "    1713, # US\tdobsonfly \tF \ttrain-clean-100\n",
    "    1716, # US\tEyeBones \tF \ttrain-clean-360\n",
    "    1814, # US\tpolkadotish \tF \ttrain-other-500\n",
    "    1709, # US\tCrowGirl \tF \ttrain-other-500\n",
    "    1763, # US\tGen Jones \tF \ttrain-clean-360\n",
    "    1808, # US \tRebecca King \tF \ttrain-clean-360\n",
    "    1811, # US\tMichelle Day \tF \ttrain-clean-360\n",
    "    1857, # US\tAmanda Friday \tF \ttrain-clean-360\n",
    "    1893, # US\tKirksVoice \tM \ttrain-other-500\n",
    "    1820, # US\tFeyaza \tF \ttrain-other-500\n",
    "    1771, # US Chelsea S. \tF \ttrain-other-500\n",
    "    1718, # US\tCaroline Driggs \tF \ttrain-other-500\n",
    "    1752, # US Shana Cohen \tF \ttrain-clean-360\n",
    "    1869, # US\tNastassiaS \tF \ttrain-other-500\n",
    "    1863, # US\tTika Sabu \tF \ttrain-other-500\n",
    "    1723, # US \tRachel Bossier \tF \ttrain-other-500\n",
    "    1798, # US\tC. L. W. Rollins \tF \ttrain-other-500\n",
    "    1755, # US Yvonne Smith \tF \ttrain-clean-360\n",
    "    1738, # US\tLois C. Johnson \tF \ttrain-clean-360\n",
    "    1887, # US \tJenna Lanman \tF \ttrain-clean-360\n",
    "]\n",
    "# chunk 10/11\n",
    "speaker_ids10_11 = [\n",
    "    1956,  # Thomas Meaney\n",
    "    2049,  # AdrianBisson\n",
    "    1978,  # John Trevithick\n",
    "    2001,  # Wesseling\n",
    "    2114,  # Larry Beasley\n",
    "    2032,  # doonaboon\n",
    "    2087,  # James Bendall\n",
    "    2011,  # pekein\n",
    "    2056,  # acloward\n",
    "    2007,  # Art Leung\n",
    "    2084,  # Eberle Thomas\n",
    "    2115,  # Pete Milan\n",
    "    1987,  # Andrew White\n",
    "    1959,  # DVoice\n",
    "    1954,  # Szindbad\n",
    "    2036,  # T.K. Kirven\n",
    "    1947,  # Barbara Edelman\n",
    "    2045,  # Linda Ciano\n",
    "    1979,  # roeg11\n",
    "    2075,  # Joy S Grape\n",
    "    2091,  # Caroline Hemmerly Kunkle\n",
    "    2023,  # Vickie Ranz\n",
    "    2014,  # Eden Rea-Hedrick\n",
    "    1965,  # redhed3095\n",
    "    1989,  # Joannemmp\n",
    "    2040,  # MJ Franck\n",
    "    1996,  # Mary in Arkansas\n",
    "    1957,  # Sarika Pawar\n",
    "    2100,  # Katherine\n",
    "    2069,  # Asta1234\n",
    "    2096,  # Tara Dow\n",
    "    2095,  # Diana Dolan\n",
    "    1995,  # Jill Janovetz\n",
    "    2017,  # CaprishaPage\n",
    "    2010,  # Peggy\n",
    "    1998,  # voicebynatalie\n",
    "    1952,  # Katalina Watt\n",
    "    2094,  # Meg Cowan\n",
    "    2065,  # Muriel\n",
    "    2312,  # Jon Kerfoot\n",
    "    2217,  # Jesse Crisp-Sears\n",
    "    2197,  # Mike Nelson\n",
    "    2282,  # Robert Snoza\n",
    "    2192,  # Sammy Bean\n",
    "    2268,  # Greg Giordano\n",
    "    2278,  # Jake Woldstad\n",
    "    2241,  # Steven Reynolds\n",
    "    2239,  # amaskill\n",
    "    2225,  # nomorejeffs\n",
    "    2283,  # Tim Cote\n",
    "    2230,  # Sam Naishtat\n",
    "    2151,  # MaxSitting\n",
    "    2141,  # KateC\n",
    "    2314,  # Cheri Jordan\n",
    "    2127,  # Ron Lockhart\n",
    "    2147,  # Shawn Bayern\n",
    "    2251,  # Wiley Combs\n",
    "    2195,  # Lynne Thompson\n",
    "    2272,  # JamesMcAndrew\n",
    "    2156,  # C F de Rosset\n",
    "    2292,  # Arnold\n",
    "    2143,  # Suebee\n",
    "    2333,  # Anita Slusser\n",
    "    2233,  # Alexis Castro\n",
    "    2305,  # Brooke Cunningham\n",
    "    2247,  # Lois Browne\n",
    "    2171,  # Carolyne\n",
    "    2172,  # Demosthenes\n",
    "    2291,  # lewildesen\n",
    "    2194,  # Iridescat\n",
    "    2331,  # Madam Fickle\n",
    "    2317,  # helengraves\n",
    "    2234,  # Coreena\n",
    "    2209,  # Samantha J Gubitz\n",
    "    2152,  # Kristel Tretter\n",
    "    2267,  # Frances Brown\n",
    "    2275,  # NatalieOram\n",
    "    2298,  # Sheila Wood\n",
    "    2138,  # Jeannie Tirado\n",
    "    2220,  # Loveday\n",
    "]\n",
    "# chunk_12\n",
    "speaker_ids12 = [\n",
    "    2403, # \tIan Quinlan \tM \ttrain-clean-360\n",
    "    2436, # IND\tjosembi \tM \ttrain-other-500\n",
    "    2387, # \tBrett G. Hirsch \tM \ttrain-other-500\n",
    "    2444, # \tdsilber01 \tM \ttrain-clean-360\n",
    "    2419, # Gary Dana \tM \ttrain-clean-100\n",
    "    2453, # \tKrzysztof Rowinski \tM \ttrain-clean-360\n",
    "    2451, #\tDeanOBuchanan \tM \ttrain-clean-100\n",
    "    2473, #\tEric Metzler \tM \ttrain-clean-360\n",
    "    2415, #\tPatrick Eaton \tM \ttrain-other-500\n",
    "    2379, #\tpjhoury \tM \ttrain-other-500\n",
    "    2377, #\tJon Kissack \tM \ttrain-clean-100\n",
    "    2355, # \tyeknod \tM \ttrain-other-500\n",
    "    2452, #\tWalt Allan \tM \ttrain-other-500\n",
    "    2401, #\tMatt Parker \tM \ttrain-clean-360\n",
    "    2359, #\tDoug Reed \tM \ttrain-other-500\n",
    "    2425, #\tnoblesavage \tM \ttrain-clean-100\n",
    "    2390, #\tsdaeley17 \tM \ttrain-clean-360\n",
    "    2461, #\tScottReyonoldsVoice \tM \ttrain-clean-360\n",
    "    2371, #\tAlexander Hatton \tM \ttrain-clean-360\n",
    "    2479, #\tDaisy Flaim \tF \ttrain-clean-100\n",
    "    2483, #\tTammy Porter \tF \ttrain-clean-360\n",
    "    2372, #\tLynne Ray \tF \ttrain-clean-360\n",
    "    2422, #\tJude Somers \tF \ttrain-clean-360\n",
    "    2357, #\tWilliam Gavula \tM \ttrain-other-500\n",
    "    2439, #\tKHand \tF \ttrain-clean-360\n",
    "    2441, # \tAlison Stewart \tF \ttrain-clean-360\n",
    "    2413, # \tJoanne Rochon \tF \ttrain-clean-360\n",
    "    2383, #\tEmma Joyce \tF \ttrain-other-500\n",
    "    2378, #\tJackie Drown \tF \ttrain-clean-360\n",
    "    2352, #\tJaimie Noy \tF \ttrain-clean-100\n",
    "    2397, # \tRebecca Braunert-Plunkett \tF \ttrain-other-500\n",
    "    2394, #\tTinaNygard2 \tF \ttrain-clean-100\n",
    "    2447, #\tDeena Rhoads \tF \ttrain-clean-360\n",
    "    2358, # \tBetty Perry \tF \ttrain-clean-360\n",
    "    2471, #\tMariaS \tF \ttrain-other-500\n",
    "    2468, #\tErin Schellhase \tF \ttrain-clean-360\n",
    "    2370, # \tgloriousjob \tM \ttrain-clean-360\n",
    "    2341, # \tHaili \tF \ttrain-other-500\n",
    "    2469, #\tKevin Owens \tM \ttrain-clean-100\n",
    "    2448, #\tEmily Maynard \tF \ttrain-clean-360\n",
    "    2351, # Nick Bulka \tM \ttrain-other-500\n",
    "]\n",
    "\n",
    "speaker_ids = speaker_ids1 + speaker_ids2 + speaker_ids3 + speaker_ids4 + speaker_ids5 + speaker_ids6 + speaker_ids7 + speaker_ids8 + speaker_ids9 + speaker_ids10_11 + speaker_ids12\n",
    "\n",
    "len(speaker_ids), len(set(speaker_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial import distance\n",
    "\n",
    "def gen_cluster_table(batch: list, embeddings: list, batch_idx: int, n_clusters: int = 3):\n",
    "    # df = pd.DataFrame(batch)\n",
    "    embeddings = np.array(embeddings) # type: ignore\n",
    "\n",
    "    # Cluster the embeddings\n",
    "    kmeans = KMeans(n_clusters=n_clusters, n_init=10).fit(embeddings)\n",
    "\n",
    "    # Add the cluster labels to your data\n",
    "    for data, label, X_s in zip(batch, kmeans.labels_, embeddings):\n",
    "        data[\"cluster\"] = label\n",
    "\n",
    "        center = kmeans.cluster_centers_[label]\n",
    "        # Calculate the distance from the cluster center\n",
    "        data[\"distance\"] = distance.euclidean(X_s, center)\n",
    "\n",
    "    df = pd.DataFrame(batch)\n",
    "\n",
    "    # Get the unique cluster labels\n",
    "    clusters = df[\"cluster\"].sort_values().unique()\n",
    "    metrics = [\"execution_time\", \"ermr\", \"jitter\", \"shimmer\", \"cluster\", \"distance\"]\n",
    "\n",
    "    demo_dirname = f\"logs/{dataset_url}_{checkpoint_name}\"\n",
    "    os.makedirs(demo_dirname, exist_ok=True)\n",
    "\n",
    "    # Add header\n",
    "    result = f\"\"\"\n",
    "    <h3>Chunk #{batch_idx}: </h3>\n",
    "    {df[[\"speaker_id\", *metrics]].describe().to_html()}\n",
    "    <h3>Chunk #{batch_idx} audio data: </h3>\n",
    "    \"\"\"\n",
    "\n",
    "    # Loop over the clusters\n",
    "    for cluster in clusters:\n",
    "        df_cluster = df[df[\"cluster\"] == cluster].sort_values(by=[\"distance\"], ascending=True)\n",
    "\n",
    "        # Add header\n",
    "        result = f\"\"\"\n",
    "        <h3>Cluster #{cluster}: </h3>\n",
    "        \"\"\"\n",
    "\n",
    "        # Generate and display the table for the chunk\n",
    "        # for _, row in df_ermr_sorted.iterrows():\n",
    "        result += gen_table(df_cluster.to_dict(\"records\")).data # type: ignore\n",
    "\n",
    "        # Save result as HTML\n",
    "        with open(f\"{demo_dirname}/chunk_{batch_idx}.html\", \"w\") as f:\n",
    "            f.write(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the voice encoder model on cuda in 0.02 seconds.\n",
      "       speaker_id  execution_time       ermr     jitter    shimmer    cluster  \\\n",
      "count   11.000000       11.000000  11.000000  11.000000  11.000000  11.000000   \n",
      "mean    26.454545        0.097273  12.196014   0.028277   0.000882   0.909091   \n",
      "std     12.266733        0.015551   6.033388   0.032268   0.000554   0.943880   \n",
      "min      8.000000        0.090000   3.170208  -0.016780   0.000061   0.000000   \n",
      "25%     16.500000        0.090000   7.291003   0.002589   0.000503   0.000000   \n",
      "50%     30.000000        0.090000  12.324289   0.025506   0.000795   1.000000   \n",
      "75%     37.000000        0.095000  17.704631   0.055425   0.001310   2.000000   \n",
      "max     42.000000        0.140000  20.255714   0.081237   0.001891   2.000000   \n",
      "\n",
      "        distance  \n",
      "count  11.000000  \n",
      "mean    0.279373  \n",
      "std     0.043543  \n",
      "min     0.223680  \n",
      "25%     0.242515  \n",
      "50%     0.291456  \n",
      "75%     0.306329  \n",
      "max     0.354393  \n",
      "clusters [0 1 2]\n",
      "       speaker_id  execution_time       ermr    jitter   shimmer  cluster  \\\n",
      "count     5.00000        5.000000   5.000000  5.000000  5.000000      5.0   \n",
      "mean     29.40000        0.092000  17.874102 -0.001882  0.000899      0.0   \n",
      "std      10.03992        0.004472   1.651620  0.009584  0.000540      0.0   \n",
      "min      18.00000        0.090000  15.619112 -0.016780  0.000061      0.0   \n",
      "25%      21.00000        0.090000  17.543665 -0.005398  0.000795      0.0   \n",
      "50%      30.00000        0.090000  17.865597  0.001297  0.000897      0.0   \n",
      "75%      36.00000        0.090000  18.086424  0.003881  0.001316      0.0   \n",
      "max      42.00000        0.100000  20.255714  0.007591  0.001427      0.0   \n",
      "\n",
      "       distance  \n",
      "count  5.000000  \n",
      "mean   0.263645  \n",
      "std    0.040883  \n",
      "min    0.223680  \n",
      "25%    0.224966  \n",
      "50%    0.260287  \n",
      "75%    0.294187  \n",
      "max    0.315106  \n",
      "       speaker_id  execution_time       ermr    jitter   shimmer  cluster  \\\n",
      "count    2.000000        2.000000   2.000000  2.000000  2.000000      2.0   \n",
      "mean    25.500000        0.100000   8.971050  0.042422  0.000503      1.0   \n",
      "std     20.506097        0.014142   4.742197  0.023923  0.000222      0.0   \n",
      "min     11.000000        0.090000   5.617810  0.025506  0.000347      1.0   \n",
      "25%     18.250000        0.095000   7.294430  0.033964  0.000425      1.0   \n",
      "50%     25.500000        0.100000   8.971050  0.042422  0.000503      1.0   \n",
      "75%     32.750000        0.105000  10.647669  0.050880  0.000582      1.0   \n",
      "max     40.000000        0.110000  12.324289  0.059338  0.000660      1.0   \n",
      "\n",
      "       distance  \n",
      "count  2.000000  \n",
      "mean   0.242515  \n",
      "std    0.000000  \n",
      "min    0.242515  \n",
      "25%    0.242515  \n",
      "50%    0.242515  \n",
      "75%    0.242515  \n",
      "max    0.242515  \n",
      "       speaker_id  execution_time      ermr    jitter   shimmer  cluster  \\\n",
      "count    4.000000          4.0000  4.000000  4.000000  4.000000      4.0   \n",
      "mean    23.250000          0.1025  6.710885  0.058903  0.001049      2.0   \n",
      "std     14.080128          0.0250  3.069590  0.016048  0.000696      0.0   \n",
      "min      8.000000          0.0900  3.170208  0.043526  0.000305      2.0   \n",
      "25%     13.250000          0.0900  4.646193  0.050522  0.000597      2.0   \n",
      "50%     23.500000          0.0900  7.051192  0.055425  0.001000      2.0   \n",
      "75%     33.500000          0.1025  9.115884  0.063807  0.001451      2.0   \n",
      "max     38.000000          0.1400  9.570948  0.081237  0.001891      2.0   \n",
      "\n",
      "       distance  \n",
      "count  4.000000  \n",
      "mean   0.317462  \n",
      "std    0.028967  \n",
      "min    0.291456  \n",
      "25%    0.296029  \n",
      "50%    0.312000  \n",
      "75%    0.333433  \n",
      "max    0.354393  \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot describe a DataFrame without columns",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 113\u001b[0m\n\u001b[1;32m    110\u001b[0m     real_idx \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    111\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[0;32m--> 113\u001b[0m gen_cluster_table(text_demo_with_metrics, embeddings, \u001b[38;5;241m999\u001b[39m)\n",
      "Cell \u001b[0;32mIn[16], line 21\u001b[0m, in \u001b[0;36mgen_cluster_table\u001b[0;34m(batch, embeddings, batch_idx, n_clusters)\u001b[0m\n\u001b[1;32m     17\u001b[0m     data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistance\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m distance\u001b[38;5;241m.\u001b[39meuclidean(X_s, center)\n\u001b[1;32m     19\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(batch)\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mdescribe())\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Get the unique cluster labels\u001b[39;00m\n\u001b[1;32m     24\u001b[0m clusters \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msort_values()\u001b[38;5;241m.\u001b[39munique()\n",
      "File \u001b[0;32m~/anaconda3/envs/tts_framework/lib/python3.11/site-packages/pandas/core/generic.py:11973\u001b[0m, in \u001b[0;36mNDFrame.describe\u001b[0;34m(self, percentiles, include, exclude)\u001b[0m\n\u001b[1;32m  11731\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m  11732\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdescribe\u001b[39m(\n\u001b[1;32m  11733\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11736\u001b[0m     exclude\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m  11737\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m  11738\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m  11739\u001b[0m \u001b[38;5;124;03m    Generate descriptive statistics.\u001b[39;00m\n\u001b[1;32m  11740\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11971\u001b[0m \u001b[38;5;124;03m    max            NaN      3.0\u001b[39;00m\n\u001b[1;32m  11972\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m> 11973\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m describe_ndframe(\n\u001b[1;32m  11974\u001b[0m         obj\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  11975\u001b[0m         include\u001b[38;5;241m=\u001b[39minclude,\n\u001b[1;32m  11976\u001b[0m         exclude\u001b[38;5;241m=\u001b[39mexclude,\n\u001b[1;32m  11977\u001b[0m         percentiles\u001b[38;5;241m=\u001b[39mpercentiles,\n\u001b[1;32m  11978\u001b[0m     )\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdescribe\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tts_framework/lib/python3.11/site-packages/pandas/core/methods/describe.py:91\u001b[0m, in \u001b[0;36mdescribe_ndframe\u001b[0;34m(obj, include, exclude, percentiles)\u001b[0m\n\u001b[1;32m     87\u001b[0m     describer \u001b[38;5;241m=\u001b[39m SeriesDescriber(\n\u001b[1;32m     88\u001b[0m         obj\u001b[38;5;241m=\u001b[39mcast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries\u001b[39m\u001b[38;5;124m\"\u001b[39m, obj),\n\u001b[1;32m     89\u001b[0m     )\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 91\u001b[0m     describer \u001b[38;5;241m=\u001b[39m DataFrameDescriber(\n\u001b[1;32m     92\u001b[0m         obj\u001b[38;5;241m=\u001b[39mcast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m, obj),\n\u001b[1;32m     93\u001b[0m         include\u001b[38;5;241m=\u001b[39minclude,\n\u001b[1;32m     94\u001b[0m         exclude\u001b[38;5;241m=\u001b[39mexclude,\n\u001b[1;32m     95\u001b[0m     )\n\u001b[1;32m     97\u001b[0m result \u001b[38;5;241m=\u001b[39m describer\u001b[38;5;241m.\u001b[39mdescribe(percentiles\u001b[38;5;241m=\u001b[39mpercentiles)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(NDFrameT, result)\n",
      "File \u001b[0;32m~/anaconda3/envs/tts_framework/lib/python3.11/site-packages/pandas/core/methods/describe.py:162\u001b[0m, in \u001b[0;36mDataFrameDescriber.__init__\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexclude \u001b[38;5;241m=\u001b[39m exclude\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot describe a DataFrame without columns\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(obj)\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot describe a DataFrame without columns"
     ]
    }
   ],
   "source": [
    "from resemblyzer import VoiceEncoder, preprocess_wav\n",
    "\n",
    "\n",
    "# text_tts = \"\"\"\n",
    "# Casablanca: “But what about us?”\n",
    "# “We’ll always have Paris.”\n",
    "# The Wizard of Oz: “Lions? And Tigers? And Bears?”\n",
    "# “Oh my!”\n",
    "# Star Wars (A New Hope): “He’s almost in range.”\n",
    "# “That’s no moon; it’s a space station.”\n",
    "# Love Story: “Jenny, I’m sorry.”\n",
    "# “Don’t. Love means never having to say you’re sorry.”\n",
    "# No Country for Old Men: “Look, I need to know what I stand to win.”\n",
    "# “Everything.”\n",
    "# Forrest Gump: “I thought I’d try out my sea legs.”\n",
    "# “But you ain’t got no legs, Lieutenant Dan.”\n",
    "# Toy Story: “Buzz, you’re flying!”\n",
    "# “This isn’t flying; this is falling with style.”\n",
    "# As the snake shook its head, a deafening shout behind Harry made both of them jump.\n",
    "# ‘DUDLEY! MR DURSLEY! COME AND LOOK AT THIS SNAKE! YOU WON’T BELIEVE WHAT IT’S DOING!’\n",
    "# \"\"\"\n",
    "\n",
    "text_tts = \"\"\"\n",
    "The Wizard of Oz: “Lions? And Tigers? And Bears?”\n",
    "“Oh my!”\n",
    "\"\"\"\n",
    "\n",
    "with open(\"training/datasets/speaker_id_mapping_libri.json\") as f:\n",
    "    id_mapping = json.load(f)\n",
    "\n",
    "batch_size = 10\n",
    "model.vocoder_module.to(device)\n",
    "\n",
    "metrics = Metrics()\n",
    "text_demo_with_metrics = []\n",
    "\n",
    "# Initialize the voice encoder\n",
    "encoder = VoiceEncoder()\n",
    "# Prepare an array to hold the embeddings\n",
    "embeddings = []\n",
    "\n",
    "speakers_df = pd.read_csv(\n",
    "    \"./datasets_cache/LIBRITTS/LibriTTS/speakers.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    names=[\"READER\", \"GENDER\", \"SUBSET\", \"NAME\"],\n",
    ")\n",
    "\n",
    "subsets = [\"train-clean-100\", \"train-clean-360\", \"train-other-500\"]\n",
    "\n",
    "speakers = speakers_df[speakers_df['SUBSET'].isin(subsets)]\n",
    "\n",
    "start_chunk = 0  # The chunk to start from\n",
    "start_idx = start_chunk * batch_size  # The index to start from\n",
    "\n",
    "speaker_ids_set = set(speaker_ids)\n",
    "\n",
    "real_idx = 0\n",
    "for idx, speaker in enumerate(speakers.to_dict(\"records\")):\n",
    "    # Skip the speakers that have already been processed\n",
    "    if idx <= start_idx:\n",
    "        continue\n",
    "\n",
    "    speaker_id = speaker[\"READER\"]\n",
    "    speaker_id = id_mapping.get(str(speaker_id))\n",
    "\n",
    "    if speaker_id is None or speaker_id not in speaker_ids_set:\n",
    "        continue\n",
    "\n",
    "    speaker_name = speaker[\"NAME\"]\n",
    "    gender = speaker[\"GENDER\"]\n",
    "    subset = speaker[\"SUBSET\"]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        speaker_id_ = torch.tensor([int(speaker_id)], device=device)\n",
    "        start_time = time.time()\n",
    "        wav = model.forward(text_tts, speaker_id_)\n",
    "        end_time = time.time()\n",
    "        (\n",
    "            ermr,\n",
    "            jitter,\n",
    "            shimmer,\n",
    "        ) = metrics.wav_metrics(wav.unsqueeze(0))\n",
    "        execution_time = round(end_time - start_time, 2)\n",
    "\n",
    "        mel = tacotronSTFT.get_mel_from_wav(wav)\n",
    "\n",
    "        # Generate an embedding for the speaker\n",
    "        embed = encoder.embed_utterance(wav.detach().cpu().numpy())\n",
    "        # Append the embedding to our list of embeddings\n",
    "        embeddings.append(embed)\n",
    "\n",
    "        text_demo_with_metrics.append({\n",
    "            \"speaker_id\": speaker_id,\n",
    "            \"speaker_name\": speaker_name,\n",
    "            \"gender\": gender,\n",
    "            \"subset\": subset,\n",
    "            \"wav\": wav.detach().cpu().numpy(),\n",
    "            \"execution_time\": execution_time,\n",
    "            \"mel\": mel.detach().cpu().numpy(),\n",
    "            \"ermr\": ermr,\n",
    "            \"jitter\": jitter,\n",
    "            \"shimmer\": shimmer,\n",
    "        })\n",
    "\n",
    "    if real_idx > 0 and real_idx % batch_size == 0:\n",
    "        gen_cluster_table(text_demo_with_metrics, embeddings, real_idx // batch_size)\n",
    "        text_demo_with_metrics = []\n",
    "        break\n",
    "\n",
    "    real_idx += 1\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "gen_cluster_table(text_demo_with_metrics, embeddings, 999)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import torchaudio\n",
    "\n",
    "# TODO: in progress\n",
    "\n",
    "# Define the speaker IDs to keep\n",
    "speaker_ids_to_keep = speaker_ids5  # Replace with your actual speaker IDs\n",
    "\n",
    "# Define the maximum audio length in seconds\n",
    "max_audio_length = 30\n",
    "\n",
    "# Define the source and destination directories\n",
    "source_dir = '/path/to/libritts'  # Replace with your actual LibriTTS directory\n",
    "dest_dir = '/path/to/libri-selected'  # Replace with your actual destination directory\n",
    "\n",
    "# Iterate over the subsets in the source directory\n",
    "for subset in os.listdir(source_dir):\n",
    "    subset_dir = os.path.join(source_dir, subset)\n",
    "\n",
    "    # Skip if not a directory\n",
    "    if not os.path.isdir(subset_dir):\n",
    "        continue\n",
    "    \n",
    "    # Iterate over the speakers in the subset\n",
    "    for speaker in os.listdir(subset_dir):\n",
    "        speaker_id = int(speaker)\n",
    "        \n",
    "        # Skip if the speaker is not in the list of speaker IDs to keep\n",
    "        if speaker_id not in speaker_ids_to_keep:\n",
    "            continue\n",
    "        \n",
    "        speaker_dir = os.path.join(subset_dir, speaker)\n",
    "        \n",
    "        # Iterate over the chapters in the speaker directory\n",
    "        for chapter in os.listdir(speaker_dir):\n",
    "            chapter_dir = os.path.join(speaker_dir, chapter)\n",
    "            \n",
    "            # Iterate over the files in the chapter directory\n",
    "            for file in os.listdir(chapter_dir):\n",
    "                if file.endswith('.wav'):\n",
    "                    file_path = os.path.join(chapter_dir, file)\n",
    "                    \n",
    "                    # Load the audio file\n",
    "                    waveform, sample_rate = torchaudio.load(file_path)\n",
    "                    \n",
    "                    # Calculate the audio length in seconds\n",
    "                    audio_length = waveform.shape[1] / sample_rate\n",
    "                    \n",
    "                    # If the audio length is less than or equal to the maximum, copy it to the destination directory\n",
    "                    if audio_length <= max_audio_length:\n",
    "                        dest_file_path = file_path.replace(source_dir, dest_dir)\n",
    "                        dest_file_dir = os.path.dirname(dest_file_path)\n",
    "                        \n",
    "                        # Create the destination directory if it doesn't exist\n",
    "                        os.makedirs(dest_file_dir, exist_ok=True)\n",
    "                        \n",
    "                        # Copy the file\n",
    "                        shutil.copyfile(file_path, dest_file_path)\n",
    "                        \n",
    "                        # Copy the associated .normalized.txt and .original.txt files\n",
    "                        for ext in ['.normalized.txt', '.original.txt']:\n",
    "                            txt_file_path = file_path.replace('.wav', ext)\n",
    "                            if os.path.exists(txt_file_path):\n",
    "                                dest_txt_file_path = txt_file_path.replace(source_dir, dest_dir)\n",
    "                                shutil.copyfile(txt_file_path, dest_txt_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
