{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268d87b8-54a2-4e09-bbef-ed28f93719f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0662705-c8a6-4588-9435-07aecb004825",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8b619e-f163-49f9-b663-c67278eb24d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "089094c9-4b03-47a8-a500-50f15d9a8ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34c26745-47fd-4ad8-9bfc-d3952a406b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./checkpoints/vocoder.ckpt'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs_base_dir = \"logs/acoustic\"\n",
    "# ckpt_acoustic = \"./checkpoints/am_pitche_stats_with_vocoder.ckpt\"\n",
    "ckpt_acoustic = \"./logs/acoustic/lightning_logs/version_1/checkpoints/epoch=5-step=66474.ckpt\"\n",
    "ckpt_vocoder = \"./checkpoints/vocoder.ckpt\"\n",
    "ckpt_vocoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de8ed1db-2d23-4f34-abad-43d287a2ffd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-c6908f57ae88bd53\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-c6908f57ae88bd53\");\n",
       "          const url = new URL(\"/proxy/6006/\", window.location);\n",
       "          const port = 0;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir {logs_base_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d26af70-b7ea-4e64-888c-106a984a3fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/tts_framework/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.callbacks import StochasticWeightAveraging\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from lightning.pytorch.tuner.tuning import Tuner\n",
    "\n",
    "from training.modules import AcousticModule, VocoderModule\n",
    "\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"]=\"1\"\n",
    "CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdbeb42-0158-4c77-874b-6fd3f72e1219",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/opt/conda/envs/tts_framework/lib/python3.11/site-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n",
      "/opt/conda/envs/tts_framework/lib/python3.11/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type               | Params\n",
      "------------------------------------------------------\n",
      "0 | acoustic_model | AcousticModel      | 38.3 M\n",
      "1 | vocoder_module | VocoderModule      | 32.6 M\n",
      "2 | loss           | FastSpeech2LossGen | 0     \n",
      "------------------------------------------------------\n",
      "70.9 M    Trainable params\n",
      "0         Non-trainable params\n",
      "70.9 M    Total params\n",
      "283.525   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  68%|██████▊   | 7487/11079 [2:26:16<1:10:10,  0.85it/s, v_num=3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  18%|█▊        | 1977/11079 [41:42<3:11:59,  0.79it/s, v_num=3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  67%|██████▋   | 7397/11079 [2:31:06<1:15:13,  0.82it/s, v_num=3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:  17%|█▋        | 1887/11079 [37:54<3:04:41,  0.83it/s, v_num=3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:  67%|██████▋   | 7385/11079 [2:28:46<1:14:25,  0.83it/s, v_num=3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  54%|█████▍    | 5984/11079 [2:02:43<1:44:29,  0.81it/s, v_num=3]"
     ]
    }
   ],
   "source": [
    "default_root_dir=\"logs/acoustic\"\n",
    "accelerator=\"cuda\"\n",
    "# ckpt_acoustic=\"./checkpoints/am_pitche_stats_with_vocoder.ckpt\"\n",
    "ckpt_acoustic=\"./logs/acoustic/lightning_logs/version_0/checkpoints/epoch=3-step=14772.ckpt\"\n",
    "ckpt_vocoder=\"./checkpoints/vocoder.ckpt\"\n",
    "accumulate_grad_batches=5\n",
    "\n",
    "tensorboard = TensorBoardLogger(save_dir=default_root_dir)\n",
    "\n",
    "trainer = Trainer(\n",
    "    logger=tensorboard,\n",
    "    # Save checkpoints to the `default_root_dir` directory\n",
    "    default_root_dir=default_root_dir,\n",
    "    accelerator=accelerator,\n",
    "    accumulate_grad_batches=accumulate_grad_batches,\n",
    "    max_epochs=-1,\n",
    ")\n",
    "\n",
    "# Load the pretrained weights for the vocoder\n",
    "vocoder_module = VocoderModule.load_from_checkpoint(\n",
    "    ckpt_vocoder,\n",
    ")\n",
    "\n",
    "module = AcousticModule.load_from_checkpoint(\n",
    "    ckpt_acoustic,\n",
    "    vocoder_module=vocoder_module,\n",
    ")\n",
    "\n",
    "# vocoder_module = VocoderModule()\n",
    "# module = AcousticModule()\n",
    "\n",
    "train_dataloader = module.train_dataloader()\n",
    "\n",
    "trainer.fit(model=module, train_dataloaders=train_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b91af306-c71d-40f2-8504-e0cecc6848a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: logs/acoustic/lightning_logs/version_0/checkpoints/ (stored 0%)\n",
      "  adding: logs/acoustic/lightning_logs/version_0/checkpoints/epoch=3-step=14772.ckpt (deflated 10%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r checkpoints.zip ./logs/acoustic/lightning_logs/version_0/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f869f3-d9fb-4241-bc06-06be8d55f305",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-tts_framework-py",
   "name": "workbench-notebooks.m111",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m111"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-env-tts_framework-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
